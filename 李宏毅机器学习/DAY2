3.回归
  a.定义：Regresssion 就是找到一个函数function ，通过输入特征 xx，输出一个数值 ScalarScalar
  b.步骤
    step 1:Model（模型假设，选择模型框架（线性模型））
          一元线性模型（单个特征）：线性模型假设 y = b + w·x_{cp}y=b+w⋅x1 （x1为特征）
          多元线性模型（多个特征）： 线性模型 Linear model：y = b+∑WiXi  （Xi各种特征，Wi各个特征的权重，b为偏移量）

    step 2:Goodness of Function （模型评估，如何判断众多模型的好坏（损失函数））
          使用损失函数（Loss function） 来衡量模型的好坏
          损失函数 Loss function：L(w,b)=∑(y^n-(W*Xcp))^2    (此处y是真实值)
    Step 3:Gradient Descent  （模型优化，如何筛选最优的模型（梯度下降））
           对于模型中的w,b的确定
           步骤1：随机选取一个w0，b0
           步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向：大于0向右移动（增加w），小于0向左移动（减少w）
           步骤3：根据学习率移动
           重复步骤2和步骤3，直到找到最低点
  c.改进训练好的模型
    1.一元N次线性模型（在一定次数内可以减少测试集误差，超过之后出现过拟合，训练集的误差降低但测试集误差增多）
    2.步骤优化
          step1 将多个线性模型合并到一个线性模型
          step2 引入更多的参数
          step3 加入正则化  L(w,b)=∑(y^n-(W*Xcp))^2 +λ∑(Wi)^2   (λ 取值要适当,Wi越小，函数越光滑，结果更准确,b无影响)
